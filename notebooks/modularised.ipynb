{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from jupyterthemes import jtplot\n",
    "#jtplot.style(theme='chesterish')\n",
    "import pickle\n",
    "from scipy.spatial.distance import euclidean #used for fdt\n",
    "import fastdtw as fdt #fast dynamic time warping\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose #decompose seasonality\n",
    "from statsmodels.tsa.stattools import adfuller #test if series is stationary (then can perform ARIMA)\n",
    "\n",
    "from pmdarima.arima import auto_arima\n",
    "import xgboost as xgb #xgboost model\n",
    "import tensorflow as tf #DNN estimator model\n",
    "%matplotlib inline\n",
    "path = '../input/'\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Flatten\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from keras import optimizers, models\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [16,9]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "DATA_DIR = r'C:\\Users\\yashc\\DataspellProjects\\DemandForecastingGCP/forecasting_ensemble/data/raw/store_item/'\n",
    "LSTM_MODEL_DIR = r'C:\\Users\\yashc\\DataspellProjects\\DemandForecastingGCP\\forecasting_ensemble\\models'\n",
    "TRAIN_PATH = DATA_DIR + 'train.csv'\n",
    "TEST_PATH = DATA_DIR + 'test.csv'\n",
    "GROUPED_COLS = ['item','store','date']\n",
    "LABEL_COL = 'sales'\n",
    "INDEX_COL = 'date'\n",
    "\n",
    "LSTM_PARAMS = {\n",
    "    'LSTM_WINDOW_LENGTH':29,\n",
    "    'LSTM_PREDICTION_LAG':90,\n",
    "    'LSTM_NODES':30,\n",
    "    'LSTM_EPOCHS':10,\n",
    "    'LSTM_BATCH':256,\n",
    "    'LSTM_LR':0.001\n",
    "}\n",
    "\n",
    "XGB_PARAMS = {\n",
    "    'XGB_MAX_DEPTH':3,\n",
    "    'XGB_ETA':0.2,\n",
    "    'XGB_SILENT':1,\n",
    "    'XGB_SUBSAMPLE':1,\n",
    "    'XGB_NUM_ROUNDS':1000\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "def SMAPE (forecast, actual):\n",
    "    \"\"\"Returns the Symmetric Mean Absolute Percentage Error between two Series\"\"\"\n",
    "    masked_arr = ~((forecast==0)&(actual==0))\n",
    "    diff = abs(forecast[masked_arr] - actual[masked_arr])\n",
    "    avg = (abs(forecast[masked_arr]) + abs(actual[masked_arr]))/2\n",
    "\n",
    "    print('SMAPE Error Score: ' + str(round(sum(diff/avg)/len(forecast) * 100, 2)) + ' %')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "def Fuller(TimeSeries):\n",
    "    \"\"\"Provides Fuller test results for TimeSeries\"\"\"\n",
    "    stationary_test = adfuller(TimeSeries)\n",
    "    print('ADF Statistic: %f' % stationary_test[0])\n",
    "    print('p-value: %f' % stationary_test[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in stationary_test[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "def xboost(x_train, y_train, x_test, xgb_params):\n",
    "    \"\"\"Trains xgboost model and returns it\"\"\"\n",
    "\n",
    "    dtrain = xgb.DMatrix(x_train, label=y_train, feature_names=list(x_train.columns))\n",
    "    dtest = xgb.DMatrix(x_test, feature_names=list(x_test.columns))\n",
    "\n",
    "    params = {'max_depth':xgb_params['XGB_MAX_DEPTH'],\n",
    "              'eta':xgb_params['XGB_ETA'],\n",
    "              'silent':xgb_params['XGB_SILENT'],\n",
    "              'subsample':xgb_params['XGB_SUBSAMPLE']}\n",
    "\n",
    "    xgb_model = xgb.train(params, dtrain, xgb_params['XGB_NUM_ROUNDS'])\n",
    "\n",
    "    return xgb_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "def lstm_model(params,x_train, y_train, x_valid, y_valid, lstm_model_dir,is_trained=0):\n",
    "\n",
    "    folder_name = datetime.now().strftime(\"%m-%d-%Y-%H-%M-%S\")\n",
    "    save_path = f'model-{folder_name}'\n",
    "\n",
    "    if is_trained:\n",
    "        fnf = listdir(lstm_model_dir)\n",
    "        sorted_lstm_models = [x for x in fnf if ('model' in str(x)) & ('xgb' not in str(x))]\n",
    "        sorted_lstm_models.sort(reverse=True)\n",
    "        model_lstm = models.load_model(sorted_lstm_models[0])\n",
    "\n",
    "    else:\n",
    "        model_lstm = Sequential()\n",
    "        model_lstm.add(LSTM(params['LSTM_NODES'], activation='relu', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "        model_lstm.add(Dense(1))\n",
    "        model_lstm.compile(loss='mse', optimizer=adam)\n",
    "        model_lstm.summary()\n",
    "        lstm_history = model_lstm.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=epochs, verbose=True)\n",
    "        model_lstm.save(save_path)\n",
    "    \n",
    "    return model_lstm\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "def read_data(path, date_index_col):\n",
    "    if path:\n",
    "        df = pd.read_csv(path, index_col=date_index_col, infer_datetime_format=True)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "train = read_data(TRAIN_PATH, 0)\n",
    "test = read_data(TEST_PATH, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "# Prepare data for LSTM\n",
    "def lstm_data_preprocessing(data, grouped_cols, label_col, date_col='date'):\n",
    "    # Rearrange dataset so we can apply shift methods\n",
    "    data = data.reset_index()\n",
    "    data = data.sort_values(date_col).groupby(grouped_cols, as_index=False)\n",
    "    data = data.agg({f'{label_col}':['mean']})\n",
    "    data.columns = grouped_cols + [label_col]\n",
    "    return data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "def xgboost_data_preprocessing(data,date_col):\n",
    "\n",
    "    # Adding date based features\n",
    "    data[date_col] = pd.to_datetime(data[date_col])\n",
    "    data['year'] = data[date_col].dt.year\n",
    "    data['quarter'] = data[date_col].dt.quarter\n",
    "    data['month'] = data[date_col].dt.month\n",
    "    data['weekofyear'] = data[date_col].dt.weekofyear\n",
    "    data['weekday'] = data[date_col].dt.weekday\n",
    "    data['dayofweek'] = data[date_col].dt.dayofweek"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "# Transform the data into a time series problem\n",
    "\n",
    "def series_to_supervised(data, window=1, lag=1, dropnan=True):\n",
    "\n",
    "    # Drop date column from data\n",
    "    data.drop('date', axis=1, inplace=True)\n",
    "\n",
    "    cols, names = list(), list()\n",
    "\n",
    "    # Input sequence (t-n, ... t-1)\n",
    "    for i in range(window, 0, -1):\n",
    "        cols.append(data.shift(i))\n",
    "        names += [('%s(t-%d)' % (col, i)) for col in data.columns]\n",
    "\n",
    "    # Current timestep (t=0)\n",
    "    cols.append(data)\n",
    "    names += [('%s(t)' % (col)) for col in data.columns]\n",
    "\n",
    "    # Target timestep (t=lag)\n",
    "    cols.append(data.shift(-lag))\n",
    "    names += [('%s(t+%d)' % (col, lag)) for col in data.columns]\n",
    "\n",
    "    # Put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    print(agg.columns)\n",
    "    # Drop rows with different item or store values than the shifted columns\n",
    "\n",
    "    last_item = 'item(t-%d)' % window\n",
    "    last_store = 'store(t-%d)' % window\n",
    "    agg = agg[(agg['store(t)'] == agg[last_store])]\n",
    "    agg = agg[(agg['item(t)'] == agg[last_item])]\n",
    "\n",
    "    columns_to_drop = [('%s(t+%d)' % (col, lag)) for col in ['item', 'store']]\n",
    "    for i in range(window, 0, -1):\n",
    "        columns_to_drop += [('%s(t-%d)' % (col, i)) for col in ['item', 'store']]\n",
    "    agg.drop(columns_to_drop, axis=1, inplace=True)\n",
    "    agg.drop(['item(t)', 'store(t)'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    # Label\n",
    "    labels_col = 'sales(t+%d)' % lag\n",
    "    labels = agg[labels_col]\n",
    "    agg = agg.drop(labels_col, axis=1)\n",
    "\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split(agg, labels.values, test_size=0.4, random_state=0)\n",
    "    # print('Train set shape', X_train.shape)\n",
    "    # print('Validation set shape', X_valid.shape)\n",
    "    # X_train.head()\n",
    "\n",
    "    X_train_series = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_valid_series = X_valid.values.reshape((X_valid.shape[0], X_valid.shape[1], 1))\n",
    "    print('Train set shape', X_train_series.shape)\n",
    "    print('Validation set shape', X_valid_series.shape)\n",
    "\n",
    "    return X_train_series, Y_train, X_valid_series, Y_valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "lstm_processed_data = lstm_data_preprocessing(train, GROUPED_COLS, LABEL_COL, INDEX_COL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['item(t-29)', 'store(t-29)', 'sales(t-29)', 'item(t-28)', 'store(t-28)',\n",
      "       'sales(t-28)', 'item(t-27)', 'store(t-27)', 'sales(t-27)', 'item(t-26)',\n",
      "       'store(t-26)', 'sales(t-26)', 'item(t-25)', 'store(t-25)',\n",
      "       'sales(t-25)', 'item(t-24)', 'store(t-24)', 'sales(t-24)', 'item(t-23)',\n",
      "       'store(t-23)', 'sales(t-23)', 'item(t-22)', 'store(t-22)',\n",
      "       'sales(t-22)', 'item(t-21)', 'store(t-21)', 'sales(t-21)', 'item(t-20)',\n",
      "       'store(t-20)', 'sales(t-20)', 'item(t-19)', 'store(t-19)',\n",
      "       'sales(t-19)', 'item(t-18)', 'store(t-18)', 'sales(t-18)', 'item(t-17)',\n",
      "       'store(t-17)', 'sales(t-17)', 'item(t-16)', 'store(t-16)',\n",
      "       'sales(t-16)', 'item(t-15)', 'store(t-15)', 'sales(t-15)', 'item(t-14)',\n",
      "       'store(t-14)', 'sales(t-14)', 'item(t-13)', 'store(t-13)',\n",
      "       'sales(t-13)', 'item(t-12)', 'store(t-12)', 'sales(t-12)', 'item(t-11)',\n",
      "       'store(t-11)', 'sales(t-11)', 'item(t-10)', 'store(t-10)',\n",
      "       'sales(t-10)', 'item(t-9)', 'store(t-9)', 'sales(t-9)', 'item(t-8)',\n",
      "       'store(t-8)', 'sales(t-8)', 'item(t-7)', 'store(t-7)', 'sales(t-7)',\n",
      "       'item(t-6)', 'store(t-6)', 'sales(t-6)', 'item(t-5)', 'store(t-5)',\n",
      "       'sales(t-5)', 'item(t-4)', 'store(t-4)', 'sales(t-4)', 'item(t-3)',\n",
      "       'store(t-3)', 'sales(t-3)', 'item(t-2)', 'store(t-2)', 'sales(t-2)',\n",
      "       'item(t-1)', 'store(t-1)', 'sales(t-1)', 'item(t)', 'store(t)',\n",
      "       'sales(t)', 'item(t+90)', 'store(t+90)', 'sales(t+90)'],\n",
      "      dtype='object')\n",
      "Train set shape (539046, 30, 1)\n",
      "Validation set shape (359364, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_series, Y_train, X_valid_series, Y_valid = series_to_supervised(lstm_processed_data, window=LSTM_PARAMS['LSTM_WINDOW_LENGTH'], lag=LSTM_PARAMS['LSTM_PREDICTION_LAG'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}